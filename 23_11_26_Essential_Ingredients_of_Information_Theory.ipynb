{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy, Mutual Information, KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sims Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_char_behaviour():\n",
    "    actions = [\"Cook a Meal\", \"Watch TV\", \"Go to Work\", \"Read a Book\", \"Go to Sleep\", \"Use the Bathroom\", \"Gardening\"]\n",
    "    return random.choice(actions)\n",
    "\n",
    "def animal_char_behaviour():\n",
    "    actions = [\"Sleep\", \"Eat\", \"Play with Toys\"]\n",
    "    return random.choice(actions)\n",
    "\n",
    "def simulate_char_behaviour(char_behaviour_function, num_iterations):\n",
    "    behaviors = [char_behaviour_function() for _ in range(num_iterations)]\n",
    "    return behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(behaviours):\n",
    "    behaviour_counts = {behaviour: behaviours.count(behaviour) for behaviour in set(behaviours)}\n",
    "    probabilities = [count / len(behaviours) for count in behaviour_counts.values()]\n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for Human Character Actions: 2.7645950264217274\n",
      "Entropy for Animal Character Actions: 1.5653996334852498\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 100\n",
    "\n",
    "human_char_actions = simulate_char_behaviour(human_char_behaviour, num_iterations)\n",
    "animal_char_actions = simulate_char_behaviour(animal_char_behaviour, num_iterations)\n",
    "\n",
    "human_char_entropy = compute_entropy(human_char_actions)\n",
    "animal_char_entropy = compute_entropy(animal_char_actions)\n",
    "\n",
    "print(\"Entropy for Human Character Actions:\", human_char_entropy) \n",
    "print(\"Entropy for Animal Character Actions:\", animal_char_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for (Normal) Human Character Actions: 2.7656936811347506\n",
      "Entropy for Hardworking Human Character Actions: 2.419799105088418\n"
     ]
    }
   ],
   "source": [
    "def hardworking_human_char_behaviour():\n",
    "    actions = [\"Cook a Meal\", \"Watch TV\", \"Go to Work\", \"Read a Book\", \"Go to Sleep\", \"Use the Bathroom\", \"Gardening\"]\n",
    "    probs = [0.05, 0.05, 0.4, 0.15, 0.15, 0.15, 0.05]\n",
    "    return random.choices(actions, weights=probs)[0]\n",
    "\n",
    "num_iterations = 100\n",
    "\n",
    "human_char_actions = simulate_char_behaviour(human_char_behaviour, num_iterations)\n",
    "hardworking_human_char_actions = simulate_char_behaviour(hardworking_human_char_behaviour, num_iterations)\n",
    "\n",
    "human_char_entropy = compute_entropy(human_char_actions)\n",
    "hardworking_human_char_entropy = compute_entropy(hardworking_human_char_actions)\n",
    "\n",
    "print(\"Entropy for (Normal) Human Character Actions:\", human_char_entropy) \n",
    "print(\"Entropy for Hardworking Human Character Actions:\", hardworking_human_char_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mutual_info(prob_matrix):\n",
    "    marginal_x = np.sum(prob_matrix, axis=1)\n",
    "    marginal_y = np.sum(prob_matrix, axis=0)\n",
    "\n",
    "    mi = 0.0\n",
    "\n",
    "    for i in range(prob_matrix.shape[0]):\n",
    "        for j in range(prob_matrix.shape[1]):\n",
    "            p_xy = prob_matrix[i, j]\n",
    "            p_x = marginal_x[i]\n",
    "            p_y = marginal_y[j]\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if p_x > 0 and p_y > 0 and p_xy > 0:\n",
    "                mi += p_xy * np.log2(p_xy / (p_x * p_y))\n",
    "\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information between hunger and energy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# joint prob  | Low Energy | High Energy\n",
    "# ------------|--------------------------          \n",
    "# Low Hunger  |     0.0    |     0.5\n",
    "# High Hunger |     0.5    |     0.0\n",
    "\n",
    "hunger_energy_matrix = np.array([[0, 0.5],\n",
    "                                 [0.5, 0]])\n",
    "\n",
    "hunger_energy_mi = compute_mutual_info(hunger_energy_matrix)\n",
    "\n",
    "print(\"Mutual information between hunger and energy:\", hunger_energy_mi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information between social skill and cooking skill: 0.0\n"
     ]
    }
   ],
   "source": [
    "# joint prob  | Bad Cooking | Good Cooking\n",
    "# ------------|---------------------------          \n",
    "# Bad Social  |     0.25    |     0.25\n",
    "# Good Social |     0.25    |     0.25\n",
    "\n",
    "social_cooking_matrix = np.array([[0.25, 0.25],\n",
    "                                 [0.25, 0.25]])\n",
    "\n",
    "social_cooking_mi = compute_mutual_info(social_cooking_matrix)\n",
    "\n",
    "print(\"Mutual information between social skill and cooking skill:\", social_cooking_mi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_divergence(p, q):\n",
    "    # Avoiding division by zero\n",
    "    q_nonzero = np.where(q == 0, 1e-10, q)\n",
    "    kl_divergence = np.sum(p * np.log2(p / q_nonzero))\n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence (Happiness vs. Money) - Bad Approximator: 10.393365233876755\n",
      "KL Divergence (Happiness vs. Money) - Good Approximator: 0.05902742206850159\n"
     ]
    }
   ],
   "source": [
    "# True distribution\n",
    "# -----------------\n",
    "# joint prob  | Poor | Rich\n",
    "# ------------|-------------    \n",
    "# Sad         | 0.30  | 0.10\n",
    "# Happy       | 0.25  | 0.35\n",
    "\n",
    "true_happiness_money_matrix = np.array([[0.30, 0.10],\n",
    "                                        [0.25, 0.35]])\n",
    "\n",
    "# Estimated distribution (Bad)\n",
    "# -----------------------------\n",
    "# joint prob  | Poor | Rich\n",
    "# ------------|-------------    \n",
    "# Sad         | 0.5  | 0.0\n",
    "# Happy       | 0.0  | 0.5\n",
    "\n",
    "bad_estimated_happiness_money_matrix = np.array([[0.5, 0.0],\n",
    "                                                 [0.0, 0.5]])\n",
    "\n",
    "# Estimated distribution (Good)\n",
    "# -----------------------------\n",
    "# joint prob  | Poor | Rich\n",
    "# ------------|-------------    \n",
    "# Sad         | 0.35  | 0.15\n",
    "# Happy       | 0.15  | 0.35\n",
    "\n",
    "good_estimated_happiness_money_matrix = np.array([[0.35, 0.15],\n",
    "                                                  [0.15, 0.35]])\n",
    "\n",
    "kl_happiness_money_bad = compute_kl_divergence(true_happiness_money_matrix,\n",
    "                                               bad_estimated_happiness_money_matrix)\n",
    "kl_happiness_money_good = compute_kl_divergence(true_happiness_money_matrix,\n",
    "                                                good_estimated_happiness_money_matrix)\n",
    "\n",
    "print(\"KL Divergence (Happiness vs. Money) - Bad Approximator:\", kl_happiness_money_bad) \n",
    "print(\"KL Divergence (Happiness vs. Money) - Good Approximator:\", kl_happiness_money_good) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More General - Binning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(X, bins):\n",
    "    binned_dist = np.histogram(X, bins)[0]\n",
    "    probs = binned_dist / np.sum(binned_dist)\n",
    "\n",
    "    # get rid of bins with zero count\n",
    "    probs = probs[np.nonzero(probs)]\n",
    "\n",
    "    entropy = - np.sum(probs * np.log2(probs))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def joint_entropy(X, Y, bins):\n",
    "    binned_dist = np.histogram2d(X, Y, bins)[0]\n",
    "    probs = binned_dist / np.sum(binned_dist)\n",
    "    probs = probs[np.nonzero(probs)]\n",
    "\n",
    "    joint_entropy = - np.sum(probs * np.log2(probs))\n",
    "\n",
    "    return joint_entropy\n",
    "\n",
    "def mutual_info(X, Y, bins):\n",
    "    H_X = entropy(X, bins)\n",
    "    H_Y = entropy(Y, bins)\n",
    "    H_XY = joint_entropy(X, Y, bins)\n",
    "\n",
    "    MI = H_X + H_Y - H_XY\n",
    "\n",
    "    return  MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin Flip Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "# 1000 trials\n",
    "for i in range(1000):\n",
    "    x_draw = random.randint(0,1)\n",
    "    y_draw = random.randint(0,1)\n",
    "    X.append(x_draw)\n",
    "    Y.append(y_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of X: 1.000\n",
      "Entropy of Y: 1.000\n",
      "Joint Entropy between X and Y: 1.999\n",
      "Mutual Information between X and Y: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f'Entropy of X: {entropy(X,2):.3f}')\n",
    "print(f'Entropy of Y: {entropy(Y,2):.3f}')\n",
    "print(f'Joint Entropy between X and Y: {joint_entropy(X,Y,2):.3f}')\n",
    "print(f'Mutual Information between X and Y: {mutual_info(X,Y,2):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "# 1000 trials\n",
    "for i in range(1000):\n",
    "    x_draw = np.random.normal(scale=100)\n",
    "    y_draw = np.random.normal(loc=x_draw)\n",
    "    X.append(x_draw)\n",
    "    Y.append(y_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of X: 1.000\n",
      "Entropy of Y: 1.000\n",
      "Joint Entropy between X and Y: 1.019\n",
      "Mutual Information between X and Y: 0.981\n"
     ]
    }
   ],
   "source": [
    "print(f'Entropy of X: {entropy(X,2):.3f}')\n",
    "print(f'Entropy of Y: {entropy(Y,2):.3f}')\n",
    "print(f'Joint Entropy between X and Y: {joint_entropy(X,Y,2):.3f}')\n",
    "print(f'Mutual Information between X and Y: {mutual_info(X,Y,2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
